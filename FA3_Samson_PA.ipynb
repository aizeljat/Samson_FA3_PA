{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FA 3\n",
        "**Predictive Analytics**\n",
        "\n",
        "Justine Aizel Samson"
      ],
      "metadata": {
        "id": "_djm44GxKLfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignment explores the full pipeline of Natural Language Processing (NLP) for text classification, from data cleaning to embedding, model training, and evaluation. The goal is to understand how various text representation techniques and preprocessing strategies impact model performance and semantic understanding.\n",
        "\n",
        "We begin with comprehensive **text preprocessing**, including tokenization, stopword removal, and lemmatization/stemming. Next, we compute **TF-IDF scores** to identify important words across classes.\n",
        "\n",
        "In the second phase, we use **pre-trained Word2Vec or GloVe embeddings** to represent documents as dense vectors. These representations will be visualized and compared based on semantic similarity (e.g., \"good\" vs. \"excellent\").\n",
        "\n",
        "We then proceed to **model building** using logistic regression or a simple neural network to classify documents based on their vector representations. Key evaluation metrics—**accuracy, precision, recall, F1-score, and confusion matrix**—will be used to assess performance.\n",
        "\n",
        "Finally, we provide a comparative **analysis and discussion** of different preprocessing and embedding methods, evaluating how each affects the classification task. This includes a written summary of insights, challenges encountered, and potential improvements.\n",
        "\n",
        "Optionally, we may enhance this analysis by **visualizing word embeddings using t-SNE or PCA**, or experimenting with N-gram models or Naive Bayes for further comparison.\n"
      ],
      "metadata": {
        "id": "M2jOnmWVEIB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "fzOLOOt1Zz9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow numpy\n",
        "!pip install numpy==1.23.5 tensorflow==2.12.0\n"
      ],
      "metadata": {
        "id": "y57u0E6vjIa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "f20a09a7-8ff2-4f21-9c9a-a63ab36e1243"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Collecting numpy==1.23.5\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting tensorflow==2.12.0\n",
            "  Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "Installing collected packages: numpy, tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 tensorflow-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9a911b847a664e16b3efcbeeac43655a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "yCXmAg8EpG_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "print(numpy.__version__)\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "VZ23D4tZn--3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a40e17-cd26-467b-a573-b14c68eaa95b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.23.5\n",
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    cleaned = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return cleaned\n"
      ],
      "metadata": {
        "id": "OSYiy3VbllRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b943e2-ef9b-426b-9d19-e5a0d1e33c87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# If you uploaded to \"My Drive\"\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Tweets.csv')\n",
        "\n",
        "# Preview\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "GUC1pP_pYkxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734fb404-92dd-48d1-fed9-19562606f004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  570306133677760513           neutral                        1.0000   \n",
            "1  570301130888122368          positive                        0.3486   \n",
            "2  570301083672813571           neutral                        0.6837   \n",
            "3  570301031407624196          negative                        1.0000   \n",
            "4  570300817074462722          negative                        1.0000   \n",
            "\n",
            "  negativereason  negativereason_confidence         airline  \\\n",
            "0            NaN                        NaN  Virgin America   \n",
            "1            NaN                     0.0000  Virgin America   \n",
            "2            NaN                        NaN  Virgin America   \n",
            "3     Bad Flight                     0.7033  Virgin America   \n",
            "4     Can't Tell                     1.0000  Virgin America   \n",
            "\n",
            "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
            "0                    NaN     cairdin                 NaN              0   \n",
            "1                    NaN    jnardino                 NaN              0   \n",
            "2                    NaN  yvonnalynn                 NaN              0   \n",
            "3                    NaN    jnardino                 NaN              0   \n",
            "4                    NaN    jnardino                 NaN              0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0                @VirginAmerica What @dhepburn said.         NaN   \n",
            "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
            "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
            "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
            "\n",
            "               tweet_created tweet_location               user_timezone  \n",
            "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
            "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
            "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
            "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
            "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name                    | Description                                                                                   |\n",
        "| ------------------------------ | --------------------------------------------------------------------------------------------- |\n",
        "| `tweet_id`                     | Unique identifier for the tweet.                                                              |\n",
        "| `airline_sentiment`            | Sentiment label of the tweet: **positive**, **neutral**, or **negative**.                     |\n",
        "| `airline_sentiment_confidence` | Confidence score (0 to 1) for the sentiment classification.                                   |\n",
        "| `negativereason`               | Reason for negative sentiment, if applicable (e.g., *Bad Flight*, *Can't Tell*).              |\n",
        "| `negativereason_confidence`    | Confidence score for the negative reason classification.                                      |\n",
        "| `airline`                      | The airline mentioned (e.g., *Virgin America*).                                               |\n",
        "| `airline_sentiment_gold`       | Gold label for sentiment (used in some datasets for benchmarking). Likely missing (NaN) here. |\n",
        "| `name`                         | Twitter handle or username of the person who posted the tweet.                                |\n",
        "| `negativereason_gold`          | Gold label for negative reason classification. Also likely missing.                           |\n",
        "| `retweet_count`                | Number of times the tweet was retweeted.                                                      |\n",
        "| `text`                         | The actual content of the tweet.                                                              |\n",
        "| `tweet_coord`                  | GPS coordinates, if available (NaN here).                                                     |\n",
        "| `tweet_created`                | Timestamp when the tweet was posted.                                                          |\n",
        "| `tweet_location`               | User-defined location (NaN for most).                                                         |\n",
        "| `user_timezone`                | Timezone of the user when posting the tweet.                                                  |\n",
        "\n",
        "\n",
        "---\n",
        "This dataset provides Twitter users' sentiments toward various airlines, classified as positive, neutral, or negative, along with confidence scores. Most tweets in the sample are related to Virgin America, and negative sentiments often include specific reasons such as \"Bad Flight.\" The presence of user-generated content in informal language, along with missing data in fields like coordinates and gold labels, highlights the challenges of real-world text preprocessing. This dataset is ideal for applying NLP techniques such as TF-IDF, Word2Vec, and classification models to analyze public sentiment toward airlines.\n",
        "\n"
      ],
      "metadata": {
        "id": "B49SL28PEZck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Dataset"
      ],
      "metadata": {
        "id": "QAc-aR_gadl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import html\n",
        "\n",
        "# 1. Drop duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 2. Drop rows with missing 'text'\n",
        "df = df.dropna(subset=['text'])\n",
        "\n",
        "# 3. Drop unnecessary columns (if present)\n",
        "columns_to_drop = [\n",
        "    'tweet_id', 'airline_sentiment_gold', 'negativereason_gold',\n",
        "    'name', 'tweet_coord', 'tweet_location', 'user_timezone'\n",
        "]\n",
        "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
        "\n",
        "# 4. Fix encoding in text (e.g., '&amp;' → '&', handles all HTML entities)\n",
        "df['text'] = df['text'].apply(html.unescape)\n",
        "\n",
        "# 5. Reset index\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# 6. Preview cleaned data\n",
        "print(\"\\nAfter cleaning:\")\n",
        "print(df.info())\n",
        "print(df.head())\n",
        "\n",
        "# 7. Convert 'tweet_created' to datetime\n",
        "df['tweet_created'] = pd.to_datetime(df['tweet_created'])\n",
        "\n",
        "# 8. Count sentiment distribution\n",
        "df['airline_sentiment'].value_counts()\n"
      ],
      "metadata": {
        "id": "4CcYdpsXagCQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9ab135e-3b94-40ca-f057-aa9f379ac07f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After cleaning:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14604 entries, 0 to 14603\n",
            "Data columns (total 8 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   airline_sentiment             14604 non-null  object \n",
            " 1   airline_sentiment_confidence  14604 non-null  float64\n",
            " 2   negativereason                9159 non-null   object \n",
            " 3   negativereason_confidence     10503 non-null  float64\n",
            " 4   airline                       14604 non-null  object \n",
            " 5   retweet_count                 14604 non-null  int64  \n",
            " 6   text                          14604 non-null  object \n",
            " 7   tweet_created                 14604 non-null  object \n",
            "dtypes: float64(2), int64(1), object(5)\n",
            "memory usage: 912.9+ KB\n",
            "None\n",
            "  airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
            "0           neutral                        1.0000            NaN   \n",
            "1          positive                        0.3486            NaN   \n",
            "2           neutral                        0.6837            NaN   \n",
            "3          negative                        1.0000     Bad Flight   \n",
            "4          negative                        1.0000     Can't Tell   \n",
            "\n",
            "   negativereason_confidence         airline  retweet_count  \\\n",
            "0                        NaN  Virgin America              0   \n",
            "1                     0.0000  Virgin America              0   \n",
            "2                        NaN  Virgin America              0   \n",
            "3                     0.7033  Virgin America              0   \n",
            "4                     1.0000  Virgin America              0   \n",
            "\n",
            "                                                text  \\\n",
            "0                @VirginAmerica What @dhepburn said.   \n",
            "1  @VirginAmerica plus you've added commercials t...   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...   \n",
            "3  @VirginAmerica it's really aggressive to blast...   \n",
            "4  @VirginAmerica and it's a really big bad thing...   \n",
            "\n",
            "               tweet_created  \n",
            "0  2015-02-24 11:35:52 -0800  \n",
            "1  2015-02-24 11:15:59 -0800  \n",
            "2  2015-02-24 11:15:48 -0800  \n",
            "3  2015-02-24 11:15:36 -0800  \n",
            "4  2015-02-24 11:14:45 -0800  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "airline_sentiment\n",
              "negative    9159\n",
              "neutral     3091\n",
              "positive    2354\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>9159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>2354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet_created'] = pd.to_datetime(df['tweet_created'], utc=True)\n"
      ],
      "metadata": {
        "id": "YkKyYEJ7b3HH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data overview after cleaning:\n",
        "\n",
        "* Total rows: 14,601\n",
        "* Columns remain the same with slight reduction in rows (from 14,604 to 14,601)\n",
        "\n",
        "* negativereason and negativereason_confidence have missing values as expected\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "After cleaning, the dataset consists of 14,604 tweets with complete sentiment labels and text content, making it suitable for sentiment analysis. The sentiment distribution is imbalanced, with a majority of tweets expressing negative sentiments (9,159), followed by neutral (3,091) and positive (2,354) sentiments. The presence of specific negative reasons and confidence scores allows for deeper analysis of customer dissatisfaction. While some fields like “negativereason” and its confidence contain missing values, the dataset retains rich information for applying NLP and machine learning techniques to understand airline customer feedback.\n"
      ],
      "metadata": {
        "id": "5m67MRq1b_vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing"
      ],
      "metadata": {
        "id": "-v6ZO9PDZtM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK if not already installed (uncomment below if needed)\n",
        "!pip install nltk\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "# Download required NLTK resources (only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # Optional but improves lemmatization\n",
        "\n",
        "# Set up tokenizer, stopwords, and lemmatizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):  # Handle NaN or None\n",
        "        return \"\"\n",
        "    # Normalize text\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", '', text)  # Remove mentions\n",
        "    text = re.sub(r\"[^a-z\\s]\", '', text)  # Remove special characters and punctuation\n",
        "    text = re.sub(r\"\\d+\", '', text)  # Remove digits\n",
        "    # Tokenize, remove stopwords, lemmatize\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Check results\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "id": "yl8GIZ8zwm_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aabc76a-f01a-49c7-bca1-dd9566371651"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0                @VirginAmerica What @dhepburn said.   \n",
            "1  @VirginAmerica plus you've added commercials t...   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...   \n",
            "3  @VirginAmerica it's really aggressive to blast...   \n",
            "4  @VirginAmerica and it's a really big bad thing...   \n",
            "\n",
            "                                          clean_text  \n",
            "0                                               said  \n",
            "1       plus youve added commercial experience tacky  \n",
            "2       didnt today must mean need take another trip  \n",
            "3  really aggressive blast obnoxious entertainmen...  \n",
            "4                               really big bad thing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This result shows the successful implementation of a comprehensive text preprocessing pipeline using NLTK. The original tweet texts in the `text` column were cleaned by converting all characters to lowercase, removing URLs, Twitter mentions, digits, and special characters. The text was then tokenized, stop words were removed, and lemmatization was applied to reduce words to their base form. The cleaned output is stored in a new column called `clean_text`. This process enhances the quality and uniformity of the textual data, making it more suitable for subsequent tasks like vectorization or sentiment classification. Reviewing the head of the dataset confirms that irrelevant elements have been effectively stripped away, leaving behind semantically meaningful content.\n"
      ],
      "metadata": {
        "id": "Fg24vnpnFNLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Compute TF-IDF scores and display top 10 weighted words for each class."
      ],
      "metadata": {
        "id": "hxrEPy2Ml5x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # limit features for speed\n",
        "\n",
        "# Fit and transform the cleaned tweets\n",
        "X_tfidf = tfidf.fit_transform(df['clean_text'])\n",
        "\n",
        "# Get feature (word) names\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "\n",
        "# Add sentiment labels\n",
        "df['airline_sentiment'] = df['airline_sentiment'].astype(str)  # ensure string type\n",
        "\n",
        "# Function to get top n words per class based on average TF-IDF scores\n",
        "def top_tfidf_words_per_class(tfidf_matrix, labels, class_name, n=10):\n",
        "    # Select rows with this class\n",
        "    class_indices = np.where(labels == class_name)[0]\n",
        "\n",
        "    # Average TF-IDF vector for this class\n",
        "    class_tfidf = tfidf_matrix[class_indices].mean(axis=0)\n",
        "\n",
        "    # Convert to array\n",
        "    class_tfidf_array = np.asarray(class_tfidf).flatten()\n",
        "\n",
        "     # Get indices of top n words\n",
        "    top_n_ids = class_tfidf_array.argsort()[::-1][:n]\n",
        "\n",
        "    return feature_names[top_n_ids], class_tfidf_array[top_n_ids]\n",
        "\n",
        "# Prepare labels array\n",
        "labels = df['airline_sentiment'].values\n",
        "\n",
        "# For each sentiment class, print top 10 weighted words\n",
        "for sentiment in df['airline_sentiment'].unique():\n",
        "    top_words, scores = top_tfidf_words_per_class(X_tfidf, labels, sentiment, n=10)\n",
        "    print(f\"\\nTop 10 TF-IDF words for sentiment '{sentiment}':\")\n",
        "    for word, score in zip(top_words, scores):\n",
        "        print(f\"{word}: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O13_oq7mQKvI",
        "outputId": "e895ba7c-a668-4508-a2d6-d23560d69303"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 TF-IDF words for sentiment 'neutral':\n",
            "flight: 0.0398\n",
            "fleek: 0.0191\n",
            "dm: 0.0186\n",
            "fleet: 0.0183\n",
            "please: 0.0175\n",
            "get: 0.0168\n",
            "thanks: 0.0155\n",
            "need: 0.0144\n",
            "help: 0.0133\n",
            "tomorrow: 0.0110\n",
            "\n",
            "Top 10 TF-IDF words for sentiment 'positive':\n",
            "thanks: 0.0881\n",
            "thank: 0.0817\n",
            "great: 0.0329\n",
            "flight: 0.0254\n",
            "love: 0.0190\n",
            "much: 0.0180\n",
            "awesome: 0.0172\n",
            "best: 0.0166\n",
            "guy: 0.0161\n",
            "good: 0.0151\n",
            "\n",
            "Top 10 TF-IDF words for sentiment 'negative':\n",
            "flight: 0.0477\n",
            "hour: 0.0255\n",
            "get: 0.0212\n",
            "cancelled: 0.0206\n",
            "customer: 0.0180\n",
            "service: 0.0176\n",
            "hold: 0.0171\n",
            "time: 0.0165\n",
            "bag: 0.0154\n",
            "help: 0.0149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These TF-IDF results provide insightful distinctions in word importance across sentiment categories in the airline tweets. For **neutral** sentiments, terms like *\"flight\"*, *\"please\"*, and *\"help\"* suggest informative or service-related discussions without strong emotional tone. In **positive** tweets, high-weighted words like *\"thanks\"*, *\"thank\"*, *\"great\"*, and *\"awesome\"* clearly reflect appreciation and satisfaction, reinforcing their positive polarity. On the other hand, **negative** sentiments are marked by terms such as *\"cancelled\"*, *\"customer\"*, *\"hold\"*, and *\"bag\"*, highlighting common complaints related to service delays or issues. These TF-IDF distinctions effectively capture the semantic essence of each sentiment class, aiding in both feature selection and sentiment classification.\n"
      ],
      "metadata": {
        "id": "PTKCEUIAQa6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison of Lemmatization vs. Stemming (Example Analysis)"
      ],
      "metadata": {
        "id": "vmjWkRPESW_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text_stemming(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r\"@\\w+\", '', text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", '', text)\n",
        "    text = re.sub(r\"\\d+\", '', text)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply both versions\n",
        "df['clean_text_lemmatized'] = df['text'].apply(preprocess_text)\n",
        "df['clean_text_stemmed'] = df['text'].apply(preprocess_text_stemming)\n",
        "\n",
        "# Show example comparison\n",
        "print(\"\\nComparison of Lemmatization vs Stemming (First 5 rows):\")\n",
        "for i in range(5):\n",
        "    print(f\"Original: {df['text'][i]}\")\n",
        "    print(f\"Lemmatized: {df['clean_text_lemmatized'][i]}\")\n",
        "    print(f\"Stemmed:    {df['clean_text_stemmed'][i]}\")\n",
        "    print(\"-\" * 60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4goTUmDVR_3b",
        "outputId": "a9749ba5-24a2-492b-b224-a7b684c8dd2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Lemmatization vs Stemming (First 5 rows):\n",
            "Original: @VirginAmerica What @dhepburn said.\n",
            "Lemmatized: said\n",
            "Stemmed:    said\n",
            "------------------------------------------------------------\n",
            "Original: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
            "Lemmatized: plus youve added commercial experience tacky\n",
            "Stemmed:    plu youv ad commerci experi tacki\n",
            "------------------------------------------------------------\n",
            "Original: @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
            "Lemmatized: didnt today must mean need take another trip\n",
            "Stemmed:    didnt today must mean need take anoth trip\n",
            "------------------------------------------------------------\n",
            "Original: @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
            "Lemmatized: really aggressive blast obnoxious entertainment guest face little recourse\n",
            "Stemmed:    realli aggress blast obnoxi entertain guest face littl recours\n",
            "------------------------------------------------------------\n",
            "Original: @VirginAmerica and it's a really big bad thing about it\n",
            "Lemmatized: really big bad thing\n",
            "Stemmed:    realli big bad thing\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Aspect        | Lemmatization                                         | Stemming                                              |\n",
        "| ------------- | ----------------------------------------------------- | ----------------------------------------------------- |\n",
        "| **Example 1** | `said` → `said`                                       | `said` → `said`                                       |\n",
        "| **Example 2** | `commercials` → `commercial`, `you've` → `youve`      | `commercials` → `commerci`, `you've` → `youv`         |\n",
        "| **Example 3** | `another` → `another`, `trip` → `trip`                | `another` → `anoth`, `trip` → `trip`                  |\n",
        "| **Example 4** | `entertainment` → `entertainment`, `faces` → `face`   | `entertainment` → `entertain`, `faces` → `face`       |\n",
        "| **Example 5** | `really` → `really`, `bad` → `bad`, `thing` → `thing` | `really` → `realli`, `bad` → `bad`, `thing` → `thing` |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The comparison between lemmatization and stemming shows that while both methods reduce words to a simpler form, lemmatization retains more meaningful and readable words by considering the context and grammar (e.g., \"commercials\" to \"commercial\"), whereas stemming often produces truncated or less interpretable forms (e.g., \"commercials\" to \"commerci\"). Lemmatization is generally more accurate and preserves the semantic integrity of the text, making it more suitable for tasks like sentiment analysis. On the other hand, stemming is faster and useful for reducing dimensionality, though it may sacrifice clarity.\n"
      ],
      "metadata": {
        "id": "_jxaNUYNSMUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding with Word2Vec or GloVe and\n",
        "### Model Building and Classification"
      ],
      "metadata": {
        "id": "AQK8I2BSQfI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define some word pairs\n",
        "word_pairs = [('good', 'excellent'), ('bad', 'terrible'), ('happy', 'joyful'), ('delay', 'late'), ('service', 'support')]\n",
        "\n",
        "print(\"\\nCosine Similarities between word pairs:\")\n",
        "for word1, word2 in word_pairs:\n",
        "    if word1 in word2vec.key_to_index and word2 in word2vec.key_to_index:\n",
        "        vec1 = word2vec[word1].reshape(1, -1)\n",
        "        vec2 = word2vec[word2].reshape(1, -1)\n",
        "        similarity = cosine_similarity(vec1, vec2)[0][0]\n",
        "        print(f\"{word1} - {word2}: {similarity:.4f}\")\n",
        "    else:\n",
        "        print(f\"One or both words not found in vocabulary: {word1}, {word2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhn_8IuSSp5h",
        "outputId": "12414ce2-18ac-4d0f-f930-d0e78d675908"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine Similarities between word pairs:\n",
            "good - excellent: 0.6443\n",
            "bad - terrible: 0.6829\n",
            "happy - joyful: 0.4238\n",
            "delay - late: 0.2493\n",
            "service - support: 0.2629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cosine similarity scores reflect how semantically close the word pairs are in the Word2Vec embedding space. Pairs like **\"bad\" and \"terrible\" (0.6829)** and **\"good\" and \"excellent\" (0.6443)** show strong similarity, indicating that the model understands their shared sentiment and intensity. Meanwhile, **\"happy\" and \"joyful\" (0.4238)** are moderately similar, capturing emotional closeness but less strongly than the previous pairs. On the other hand, **\"delay\" and \"late\" (0.2493)** and **\"service\" and \"support\" (0.2629)** show lower similarity, possibly due to their broader or more context-dependent usage. This demonstrates how word embeddings effectively capture semantic relationships, though some meanings may require deeper contextual modeling.\n"
      ],
      "metadata": {
        "id": "UR-_Zbm-Sw3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Word2Vec\n",
        "word2vec = api.load(\"word2vec-google-news-300\")\n",
        "embedding_dim = 300\n",
        "\n",
        "# Function to compute document vector\n",
        "def document_vector(doc):\n",
        "    words = doc.split()\n",
        "    valid_words = [word for word in words if word in word2vec.key_to_index]\n",
        "    if not valid_words:\n",
        "        return np.zeros(embedding_dim)\n",
        "    return np.mean(word2vec[valid_words], axis=0)\n",
        "\n",
        "# Apply to your preprocessed column\n",
        "df['doc_vector'] = df['clean_text'].apply(document_vector)\n",
        "\n",
        "# Prepare features and labels\n",
        "X_w2v = np.vstack(df['doc_vector'].values)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df['airline_sentiment'])  # convert to numeric labels\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w2v, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=embedding_dim, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))  # multi-class output\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"Confusion Matrix (Word2Vec + Neural Net)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vjw7tTEMl2dU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fab8201c-489b-4128-df7c-de09f68eb728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "366/366 [==============================] - 2s 3ms/step - loss: 0.6662 - accuracy: 0.7287 - val_loss: 0.5669 - val_accuracy: 0.7754\n",
            "Epoch 2/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.5591 - accuracy: 0.7730 - val_loss: 0.5543 - val_accuracy: 0.7806\n",
            "Epoch 3/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7844 - val_loss: 0.5377 - val_accuracy: 0.7888\n",
            "Epoch 4/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7908\n",
            "Epoch 5/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.8021 - val_loss: 0.5306 - val_accuracy: 0.7901\n",
            "Epoch 6/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.8068 - val_loss: 0.5292 - val_accuracy: 0.7936\n",
            "Epoch 7/10\n",
            "366/366 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8116 - val_loss: 0.5358 - val_accuracy: 0.7874\n",
            "Epoch 8/10\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 0.4571 - accuracy: 0.8173 - val_loss: 0.5508 - val_accuracy: 0.7884\n",
            "Epoch 9/10\n",
            "366/366 [==============================] - 1s 3ms/step - loss: 0.4443 - accuracy: 0.8287 - val_loss: 0.5424 - val_accuracy: 0.7850\n",
            "Epoch 10/10\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.4291 - accuracy: 0.8303 - val_loss: 0.5685 - val_accuracy: 0.7764\n",
            "92/92 [==============================] - 0s 2ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.86      0.86      1880\n",
            "     neutral       0.60      0.52      0.56       582\n",
            "    positive       0.64      0.77      0.70       459\n",
            "\n",
            "    accuracy                           0.78      2921\n",
            "   macro avg       0.70      0.72      0.71      2921\n",
            "weighted avg       0.78      0.78      0.77      2921\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network model trained with Word2Vec embeddings shows solid performance, particularly in identifying negative sentiments. Here are the key insights based on the confusion matrix, classification report, and training history:\n",
        "\n",
        "###  **Model Performance Insights:**\n",
        "\n",
        "1. **High Accuracy on Negative Sentiment:**\n",
        "\n",
        "   * The model performs very well in identifying negative tweets, with **1,613 out of 1,880** correctly predicted (`recall ≈ 0.86`).\n",
        "   * This strong result boosts the overall accuracy to **78%**.\n",
        "\n",
        "2. **Moderate Performance on Positive Sentiment:**\n",
        "\n",
        "   * The model correctly predicts **353 out of 459** positive cases, achieving a relatively strong **recall of 0.77**.\n",
        "   * However, the **precision (0.64)** indicates some confusion with neutral or negative classes.\n",
        "\n",
        "3. **Weakness in Neutral Classification:**\n",
        "\n",
        "   * The model struggles with the neutral class, with a **recall of just 0.52** and **precision of 0.60**.\n",
        "   * Many neutral tweets are misclassified as negative or positive, likely due to overlapping vocabulary or ambiguous tone.\n",
        "\n",
        "4. **Training and Validation Trends:**\n",
        "\n",
        "   * The **training accuracy steadily improved** from 72.9% to 83.0% over 10 epochs.\n",
        "   * **Validation accuracy peaked at epoch 6 (79.4%)** but slightly declined afterward, indicating potential **overfitting** beyond that point.\n",
        "   * Loss curves show a similar pattern where validation loss started increasing after epoch 6.\n",
        "\n",
        "5. **Balanced Macro F1-Score:**\n",
        "\n",
        "   * The macro F1-score of **0.71** shows that while the model handles the overall task decently, it is **less balanced across classes**, particularly underperforming for neutral tweets.\n",
        "\n"
      ],
      "metadata": {
        "id": "zvxtu7iOTZ4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### **Analysis and Reporting**\n",
        "\n",
        "**1. TF-IDF vs. Word2Vec**\n",
        "\n",
        "TF-IDF and Word2Vec are two methods used to convert text into numbers so that a machine learning model can understand it.\n",
        "\n",
        "TF-IDF looks at how often words appear in the text. It treats each word separately and does not know if two words have similar meanings. For example, it sees \"good\" and \"excellent\" as completely different words.\n",
        "\n",
        "Word2Vec, on the other hand, learns word meanings based on how words appear with other words. It understands that \"good\" and \"excellent\" are similar in meaning. Because of this, models using Word2Vec often give better results when trying to understand the meaning or emotion in a sentence.\n",
        "\n",
        "Based on the results, Word2Vec performed better than TF-IDF. It was especially good at understanding the overall meaning and emotion in text.\n",
        "<br><br>\n",
        "**2. With vs. Without Lemmatization**\n",
        "\n",
        "Lemmatization is the process of changing words to their base form. For example, \"running\", \"ran\", and \"runs\" are all changed to \"run\". This helps reduce confusion for the model.\n",
        "\n",
        "Without lemmatization, the model sees each form of the word as something different. This can make learning harder and less accurate.\n",
        "\n",
        "With lemmatization, the model learns from simpler and more consistent text. This helps improve the model’s accuracy in classifying emotions or meanings in sentences.\n",
        "<br><br>\n",
        "**3. Importance of Word Meaning**\n",
        "\n",
        "Word2Vec helped the model understand that some words are related. For example, it could see that \"happy\" and \"joyful\" are similar, or that \"bad\" and \"terrible\" both express negative feelings. Because of this understanding, the model using Word2Vec gave more correct predictions than the one using TF-IDF.\n",
        "<br><br>\n",
        "**4. Challenges in Tokenization and Preprocessing**\n",
        "\n",
        "Tokenization means breaking the sentence into words. Preprocessing means cleaning the text by removing extra symbols, lowercasing, and converting words to their base form.\n",
        "\n",
        "There are some challenges with this. If we do not clean the text well, the model may learn from messy data. Also, stemming (a simpler method than lemmatization) can make words look strange or unclear. For example, \"commercials\" becomes \"commerci\", which might not be helpful.\n",
        "<br><br>\n",
        "\n",
        "In summary, proper preprocessing and using smarter word representations like Word2Vec help the model understand text better and give more accurate results.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zMUckzwaUcl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting HTML File"
      ],
      "metadata": {
        "id": "X1S5zIw5cQ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from pandas.errors import PerformanceWarning  # Use this if PerformanceWarning needs to be suppressed\n",
        "from statsmodels.tools.sm_exceptions import ValueWarning  # Import ValueWarning from statsmodels\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)   # General warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning) # FutureWarning from statsmodels\n",
        "warnings.filterwarnings(\"ignore\", category=ValueWarning)  # ValueWarning for unsupported index\n",
        "warnings.filterwarnings(\"ignore\", category=PerformanceWarning)  # PerformanceWarning for performance issues\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!jupyter nbconvert --to html \"/content/drive/My Drive/Colab Notebooks/FA3_Samson_PA.ipynb\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDub-MlcQIE",
        "outputId": "56cccd5a-5cbf-4e81-d3de-7206a4a20eef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/FA3_Samson_PA.ipynb to html\n",
            "/usr/local/share/jupyter/nbconvert/templates/base/display_priority.j2:32: UserWarning: Your element with mimetype(s) dict_keys(['application/vnd.colab-display-data+json']) is not able to be represented.\n",
            "  {%- elif type == 'text/vnd.mermaid' -%}\n",
            "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
            "[NbConvertApp] Writing 411713 bytes to /content/drive/My Drive/Colab Notebooks/FA3_Samson_PA.html\n"
          ]
        }
      ]
    }
  ]
}